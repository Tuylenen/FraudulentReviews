{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные с сохраненных веб-страниц\n",
    "\n",
    "def reading_group(html, label):\n",
    "\n",
    "    with open(html) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    author, date, text = [], [], []\n",
    "\n",
    "    comments = re.findall(r'<div class=\"bp_post clear_fix \"((.|\\n)*?)Показать список оценивших', page)\n",
    "    for comment in comments:\n",
    "        comment = comment[0]\n",
    "        author.append(re.search(r'<a class=\"bp_author\"(.*)\">(.*)</a>', comment)[2])\n",
    "        date.append(re.search(r'<a class=\"bp_date\"(.*)\">(.*)</a>', comment)[2])\n",
    "        try:\n",
    "            text.append(re.search(r'<div class=\"bp_text\">(.*)</div>', comment)[1])\n",
    "        except:\n",
    "            text.append('')\n",
    "\n",
    "    t_c, h_c, p_c = [], [], []\n",
    "\n",
    "    for comment in text:\n",
    "        href = re.findall(r\"^<a href(.*)mem_link(.*)(.*)</a>\", comment)\n",
    "        \n",
    "        ret = 'return showPhoto' in comment\n",
    "        p_c.append(ret)\n",
    "        \n",
    "        if href:        \n",
    "            h_lst = []\n",
    "            for n in href:\n",
    "                href = re.findall(r'Board.mentionOver\\(this\\)\">(.*)', n[1])\n",
    "                h_lst.append(href)\n",
    "            comment = \"{}, {}\".format(','.join(h_lst[0]), comment.split(\"</a>,\")[1])\n",
    "            h_c.append(h_lst[0])\n",
    "        else:\n",
    "            h_c.append(\"na\")\n",
    "        t_c.append(re.sub('<br><br>', '', re.sub('</?div(.*)>', '', comment)))\n",
    "\n",
    "    comments = pd.DataFrame(list(zip(author, date, t_c, h_c, p_c)),\n",
    "                            columns=['author', 'date', 'comment', 'mention', 'image'])\n",
    "    \n",
    "    if label:\n",
    "        comments['is_fake'] = 0\n",
    "    else:\n",
    "        comments['is_fake'] = 1\n",
    "    \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем датафрейм с данными каждой из подпапок\n",
    "\n",
    "def create_df(directory, label):\n",
    "    df = pd.DataFrame()\n",
    "    path = './html/' + directory\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".html\"):\n",
    "            comments = reading_group(path + '/' + filename, label)\n",
    "            df = pd.concat([df, comments], sort=True, ignore_index=True)\n",
    "        else:\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**author** - the user that posted a comment<br>\n",
    "**comment** - text of the review<br>\n",
    "**date** - when a comment was created<br>\n",
    "**image** - True (1) if photos are attached, false otherwise<br>\n",
    "**mention** - True (1) if there is a mention at the start of the message of another user, false otherwise<br>\n",
    "**is_fake** - target label, True (1) if a comment is fake, false otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>BERISHMOT Store</td>\n",
       "      <td>Степа&lt;/a&gt;, На любые Ваши вопросы ответит менед...</td>\n",
       "      <td>27 ноя 2017 в 23:25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[Степа&lt;/a&gt;, На любые Ваши вопросы ответит мене...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>Настя Воронина</td>\n",
       "      <td>Ясно. Спасибо за информацию</td>\n",
       "      <td>8 ноя 2019 в 16:12</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>Саша Климов</td>\n",
       "      <td>Заказывал Свитшот Fila.&lt;br&gt;Спасибо огромное Ви...</td>\n",
       "      <td>19 мар 2018 в 11:09</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>Максим Саркисян</td>\n",
       "      <td></td>\n",
       "      <td>22 июн 2018 в 12:07</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>Анжела Новикова</td>\n",
       "      <td>Заказывала впервые тут кроссовки Fila Disrupto...</td>\n",
       "      <td>10 апр 2018 в 9:19</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                            comment  \\\n",
       "226   BERISHMOT Store  Степа</a>, На любые Ваши вопросы ответит менед...   \n",
       "1871   Настя Воронина                        Ясно. Спасибо за информацию   \n",
       "684       Саша Климов  Заказывал Свитшот Fila.<br>Спасибо огромное Ви...   \n",
       "1143  Максим Саркисян                                                      \n",
       "832   Анжела Новикова  Заказывала впервые тут кроссовки Fila Disrupto...   \n",
       "\n",
       "                     date  image  is_fake  \\\n",
       "226   27 ноя 2017 в 23:25  False        0   \n",
       "1871   8 ноя 2019 в 16:12  False        0   \n",
       "684   19 мар 2018 в 11:09   True        0   \n",
       "1143  22 июн 2018 в 12:07  False        0   \n",
       "832    10 апр 2018 в 9:19   True        0   \n",
       "\n",
       "                                                mention  \n",
       "226   [Степа</a>, На любые Ваши вопросы ответит мене...  \n",
       "1871                                                 na  \n",
       "684                                                  na  \n",
       "1143                                                 na  \n",
       "832                                                  na  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подпапка с реальными отзывами\n",
    "\n",
    "df_true = create_df('vk/true', True).sample(n=800)\n",
    "df_true.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Вика Сергеева</td>\n",
       "      <td>Получила свои вещи, бомбер и платье безумно ра...</td>\n",
       "      <td>30 апр 2018 в 18:34</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Олександра Аравіцька</td>\n",
       "      <td>Спасибо!!!!Очень быстро и никаких проблем, даж...</td>\n",
       "      <td>1 мая 2018 в 8:32</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Олеся Фирсова</td>\n",
       "      <td>Спасибо большое , получила платьице, цвет как ...</td>\n",
       "      <td>7 мая 2018 в 12:55</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Анастасия Нестерова</td>\n",
       "      <td>Сегодня доставили мне мои шлёпки и джинсы. К к...</td>\n",
       "      <td>8 мая 2018 в 15:06</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Наталья Белоусова</td>\n",
       "      <td>Такой шикарный магазин и так мало отзывов ,это...</td>\n",
       "      <td>сегодня в 14:37</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                            comment  \\\n",
       "617         Вика Сергеева  Получила свои вещи, бомбер и платье безумно ра...   \n",
       "618  Олександра Аравіцька  Спасибо!!!!Очень быстро и никаких проблем, даж...   \n",
       "619         Олеся Фирсова  Спасибо большое , получила платьице, цвет как ...   \n",
       "620   Анастасия Нестерова  Сегодня доставили мне мои шлёпки и джинсы. К к...   \n",
       "621     Наталья Белоусова  Такой шикарный магазин и так мало отзывов ,это...   \n",
       "\n",
       "                    date  image  is_fake mention  \n",
       "617  30 апр 2018 в 18:34  False        1      na  \n",
       "618    1 мая 2018 в 8:32  False        1      na  \n",
       "619   7 мая 2018 в 12:55   True        1      na  \n",
       "620   8 мая 2018 в 15:06  False        1      na  \n",
       "621      сегодня в 14:37  False        1      na  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подпапка с фальшивыми отзывами\n",
    "\n",
    "df_false = create_df('vk/false', False)\n",
    "df_false.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Магазин кроссовок / Sniiiky</td>\n",
       "      <td>Тема только для отзывов! За отзыв с фото вы по...</td>\n",
       "      <td>21 сен 2017 в 2:16</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Анна Токарева</td>\n",
       "      <td>Сегодня забрала на почте! Качество отличное, у...</td>\n",
       "      <td>25 ноя 2017 в 6:46</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Магазин кроссовок / Sniiiky</td>\n",
       "      <td>Анна,  спасибо! &lt;img class=\"emoji_css\" alt=\"&amp;#...</td>\n",
       "      <td>25 ноя 2017 в 9:04</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>[Анна]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Анна Николаева</td>\n",
       "      <td>Вчера получила, до сих пор не нарадуюсь и про ...</td>\n",
       "      <td>27 ноя 2017 в 16:20</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Магазин кроссовок / Sniiiky</td>\n",
       "      <td>Анна,  спасибо! &lt;img class=\"emoji_css\" alt=\"&amp;#...</td>\n",
       "      <td>27 ноя 2017 в 19:22</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>[Анна]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>BERISHMOT Store</td>\n",
       "      <td>Степа&lt;/a&gt;, На любые Ваши вопросы ответит менед...</td>\n",
       "      <td>27 ноя 2017 в 23:25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[Степа&lt;/a&gt;, На любые Ваши вопросы ответит мене...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>Настя Воронина</td>\n",
       "      <td>Ясно. Спасибо за информацию</td>\n",
       "      <td>8 ноя 2019 в 16:12</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Саша Климов</td>\n",
       "      <td>Заказывал Свитшот Fila.&lt;br&gt;Спасибо огромное Ви...</td>\n",
       "      <td>19 мар 2018 в 11:09</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Максим Саркисян</td>\n",
       "      <td></td>\n",
       "      <td>22 июн 2018 в 12:07</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Анжела Новикова</td>\n",
       "      <td>Заказывала впервые тут кроссовки Fila Disrupto...</td>\n",
       "      <td>10 апр 2018 в 9:19</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1422 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           author  \\\n",
       "0     Магазин кроссовок / Sniiiky   \n",
       "1                   Анна Токарева   \n",
       "2     Магазин кроссовок / Sniiiky   \n",
       "3                  Анна Николаева   \n",
       "4     Магазин кроссовок / Sniiiky   \n",
       "...                           ...   \n",
       "1417              BERISHMOT Store   \n",
       "1418               Настя Воронина   \n",
       "1419                  Саша Климов   \n",
       "1420              Максим Саркисян   \n",
       "1421              Анжела Новикова   \n",
       "\n",
       "                                                comment                 date  \\\n",
       "0     Тема только для отзывов! За отзыв с фото вы по...   21 сен 2017 в 2:16   \n",
       "1     Сегодня забрала на почте! Качество отличное, у...   25 ноя 2017 в 6:46   \n",
       "2     Анна,  спасибо! <img class=\"emoji_css\" alt=\"&#...   25 ноя 2017 в 9:04   \n",
       "3     Вчера получила, до сих пор не нарадуюсь и про ...  27 ноя 2017 в 16:20   \n",
       "4     Анна,  спасибо! <img class=\"emoji_css\" alt=\"&#...  27 ноя 2017 в 19:22   \n",
       "...                                                 ...                  ...   \n",
       "1417  Степа</a>, На любые Ваши вопросы ответит менед...  27 ноя 2017 в 23:25   \n",
       "1418                        Ясно. Спасибо за информацию   8 ноя 2019 в 16:12   \n",
       "1419  Заказывал Свитшот Fila.<br>Спасибо огромное Ви...  19 мар 2018 в 11:09   \n",
       "1420                                                     22 июн 2018 в 12:07   \n",
       "1421  Заказывала впервые тут кроссовки Fila Disrupto...   10 апр 2018 в 9:19   \n",
       "\n",
       "      image  is_fake                                            mention  \n",
       "0     False        1                                                 na  \n",
       "1      True        1                                                 na  \n",
       "2     False        1                                             [Анна]  \n",
       "3      True        1                                                 na  \n",
       "4     False        1                                             [Анна]  \n",
       "...     ...      ...                                                ...  \n",
       "1417  False        0  [Степа</a>, На любые Ваши вопросы ответит мене...  \n",
       "1418  False        0                                                 na  \n",
       "1419   True        0                                                 na  \n",
       "1420  False        0                                                 na  \n",
       "1421   True        0                                                 na  \n",
       "\n",
       "[1422 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединяем датафреймы\n",
    "\n",
    "df = pd.concat([df_false, df_true], sort=True, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем результат в отдельный файл\n",
    "\n",
    "df.to_csv('raw.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем комментарии владельцев групп\n",
    "\n",
    "owners = ['BERISHMOT Store', 'Андрей Северец', 'Магазин кроссовок / Sniiiky',\n",
    "          'Настя Осипова', '|Мобильные телефоны|', 'RUDI ROYALE', 'NICE DEVISE | Москва',\n",
    "          'Lovely Shop - магазин женской одежды', 'Non S7op Shop (Nike~Reebok~Adidas~Asics)',\n",
    "          'Модная женская одежда \"Valum\"', \"Lady's Shop - магазин шикарной одежды\"]\n",
    "\n",
    "for i in owners:\n",
    "    df = df[df.author != i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1133, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем из текстов теги и гиперссылки\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    String cleaning: return only words\n",
    "    \"\"\"\n",
    "    string = re.sub('<.*?>', ' ', string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string\n",
    "\n",
    "df['comment'] = df['comment'].apply(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем сообщения с упоминанием пользователей\n",
    "# чаще всего это вопросы или ответы, а не отзывы\n",
    "\n",
    "df = df[df.mention == 'na']\n",
    "df = df.reset_index().drop(['mention', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indxs = df[df.comment.str.contains(\"\\?\", na=False)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(973, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[indxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем вхождения с вопросами \n",
    "\n",
    "df = df.drop(df.columns[[0]], axis=1)\n",
    "\n",
    "df.to_csv('out.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(922, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сегодня забрала на почте! Качество отличное, у...</td>\n",
       "      <td>25 ноя 2017 в 6:46</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Вчера получила, до сих пор не нарадуюсь и про ...</td>\n",
       "      <td>27 ноя 2017 в 16:20</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Спасибо большое Всё отлично! Очень нравится</td>\n",
       "      <td>28 ноя 2017 в 14:07</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment                 date  \\\n",
       "0  Сегодня забрала на почте! Качество отличное, у...   25 ноя 2017 в 6:46   \n",
       "1  Вчера получила, до сих пор не нарадуюсь и про ...  27 ноя 2017 в 16:20   \n",
       "2       Спасибо большое Всё отлично! Очень нравится   28 ноя 2017 в 14:07   \n",
       "\n",
       "   image  is_fake  \n",
       "0   True        1  \n",
       "1   True        1  \n",
       "2   True        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество реальных и фейковых отзывов в корпусе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    470\n",
       "1    452\n",
       "Name: is_fake, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_fake'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля реальных комментариев в корпусе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = df['is_fake'].value_counts()[0] / len(df['is_fake'])\n",
    "round(res, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество отзывов с приклеплёнными фотографиями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     694\n",
       "False    228\n",
       "Name: image, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть отзывов с фото для фэйковых отзывов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.695"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(df[(df.image==True) & (df.is_fake==1)]) / len(df[df.is_fake==1]), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть отзывов с фото для реальных отзывов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.809"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(df[(df.image==True) & (df.is_fake==0)]) / len(df[df.is_fake==0]), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим некоторые данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add = df.copy()\n",
    "\n",
    "df_add['count_words'] = df[\"comment\"].apply(lambda x: len(str(x).split()))\n",
    "df_add['count_unique_words'] = df[\"comment\"].apply(lambda x: len(set(str(x).split())))\n",
    "df_add['count_letters'] = df[\"comment\"].apply(lambda x: len(str(x)))\n",
    "df_add[\"count_punctuations\"] = df[\"comment\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "df_add[\"count_words_upper\"] = df[\"comment\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "df_add[\"count_words_title\"] = df[\"comment\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_unique_words</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>count_punctuations</th>\n",
       "      <th>count_words_upper</th>\n",
       "      <th>count_words_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>Пришли штаны, никаких повреждений, по качеству...</td>\n",
       "      <td>28 мар 2020 в 14:18</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>191</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Ясно. Спасибо за информацию</td>\n",
       "      <td>8 ноя 2019 в 16:12</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Заказывал Свитшот Fila. Спасибо огромное Викто...</td>\n",
       "      <td>19 мар 2018 в 11:09</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>158</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td></td>\n",
       "      <td>22 июн 2018 в 12:07</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Заказывала впервые тут кроссовки Fila Disrupto...</td>\n",
       "      <td>10 апр 2018 в 9:19</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>389</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment                 date  \\\n",
       "968  Пришли штаны, никаких повреждений, по качеству...  28 мар 2020 в 14:18   \n",
       "969                        Ясно. Спасибо за информацию   8 ноя 2019 в 16:12   \n",
       "970  Заказывал Свитшот Fila. Спасибо огромное Викто...  19 мар 2018 в 11:09   \n",
       "971                                                     22 июн 2018 в 12:07   \n",
       "972  Заказывала впервые тут кроссовки Fila Disrupto...   10 апр 2018 в 9:19   \n",
       "\n",
       "     image  is_fake  count_words  count_unique_words  count_letters  \\\n",
       "968   True        0           28                  27            191   \n",
       "969  False        0            4                   4             27   \n",
       "970   True        0           20                  20            158   \n",
       "971  False        0            0                   0              0   \n",
       "972   True        0           56                  53            389   \n",
       "\n",
       "     count_punctuations  count_words_upper  count_words_title  \n",
       "968                   6                  0                  3  \n",
       "969                   1                  0                  2  \n",
       "970                   6                  0                  7  \n",
       "971                   0                  0                  0  \n",
       "972                  11                  1                 14  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_add.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment', 'date', 'image', 'is_fake', 'count_words',\n",
       "       'count_unique_words', 'count_letters', 'count_punctuations',\n",
       "       'count_words_upper', 'count_words_title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_add.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее число слов в фейковых отзывах: 20.332\n",
      "Среднее число слов в реальных отзывах: 22.526\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее число слов в фейковых отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == True].count_words.mean(), 3)))\n",
    "print(\"Среднее число слов в реальных отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == False].count_words.mean(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее число уникальных слов в фейковых отзывах: 19.314\n",
      "Среднее число уникальных слов в реальных отзывах: 21.211\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее число уникальных слов в фейковых отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == True].count_unique_words.mean(), 3)))\n",
    "print(\"Среднее число уникальных слов в реальных отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == False].count_unique_words.mean(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее число символов в фейковых отзывах: 141.219\n",
      "Среднее число символов в реальных отзывах: 150.279\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее число символов в фейковых отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == True].count_letters.mean(), 3)))\n",
    "print(\"Среднее число символов в реальных отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == False].count_letters.mean(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее число знаков пунктуации в фейковых отзывах: 6.814\n",
      "Среднее число знаков пунктуации в реальных отзывах: 6.219\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее число знаков пунктуации в фейковых отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == True].count_punctuations.mean(), 3)))\n",
    "print(\"Среднее число знаков пунктуации в реальных отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == False].count_punctuations.mean(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее число слов в верхнем регистре в фейковых отзывах: 0.219\n",
      "Среднее число слов в верхнем регистре в реальных отзывах: 0.47\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее число слов в верхнем регистре в фейковых отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == True].count_words_upper.mean(), 3)))\n",
    "print(\"Среднее число слов в верхнем регистре в реальных отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == False].count_words_upper.mean(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее число слов, написанных с заглавной буквы, в фейковых отзывах: 2.482\n",
      "Среднее число слов, написанных с заглавной буквы, в реальных отзывах: 3.594\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее число слов, написанных с заглавной буквы, в фейковых отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == True].count_words_title.mean(), 3)))\n",
    "print(\"Среднее число слов, написанных с заглавной буквы, в реальных отзывах: {}\".\n",
    "      format(round(df_add[df_add.is_fake == False].count_words_title.mean(), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# составим список, включающий в себя все уникальные слова корпуса\n",
    "# лемматизируем слова\n",
    "\n",
    "vocabulary = []\n",
    "numWords = []\n",
    "lemmatized_texts = []\n",
    "\n",
    "def text_lemmatize(text):\n",
    "    global vocabulary \n",
    "    global numWords\n",
    "    try:\n",
    "        text = re.sub(r\"[^А-Яа-яё]\", \" \", text).strip()\n",
    "        ps = Mystem()\n",
    "        text = ps.lemmatize(text)\n",
    "        lemmatized_texts.append(text)\n",
    "        vocabulary.extend(text)\n",
    "        numWords.append(len(text))\n",
    "        return ' '.join(text)\n",
    "    except:\n",
    "        lemmatized_texts.append('')\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem = df.copy()\n",
    "df_lem['comment'] = df_lem['comment'].apply(text_lemmatize)\n",
    "\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(numWords, 100)\n",
    "plt.xlabel('Review Length in Words')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего отзывов:  922\n",
      "Всего слов:  38550\n",
      "Всего уникальных слов:  2006\n",
      "Средняя длина отзыва в словах:  41.81127982646421\n"
     ]
    }
   ],
   "source": [
    "print('Всего отзывов: ', len(numWords))\n",
    "print('Всего слов: ', sum(numWords))\n",
    "print('Всего уникальных слов: ', len(vocabulary))\n",
    "print('Средняя длина отзыва в словах: ', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>сегодня   забирать   на   почта    качество   ...</td>\n",
       "      <td>25 ноя 2017 в 6:46</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[сегодня,  , забирать,  , на,  , почта,   , ка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вчера   получать    до   сей   пора   не   нар...</td>\n",
       "      <td>27 ноя 2017 в 16:20</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[вчера,  , получать,   , до,  , сей,  , пора, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>спасибо   большой   все   отличный    очень   ...</td>\n",
       "      <td>28 ноя 2017 в 14:07</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[спасибо,  , большой,  , все,  , отличный,   ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>спасибо   за   офигенный   кросс \\n</td>\n",
       "      <td>1 дек 2017 в 20:55</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[спасибо,  , за,  , офигенный,  , кросс, \\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>все   получать    переживать   за   качество  ...</td>\n",
       "      <td>2 дек 2017 в 17:22</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[все,  , получать,   , переживать,  , за,  , к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>приходить   штаны    никакой   повреждение    ...</td>\n",
       "      <td>28 мар 2020 в 14:18</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[приходить,  , штаны,   , никакой,  , поврежде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>ясно    спасибо   за   информация \\n</td>\n",
       "      <td>8 ноя 2019 в 16:12</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[ясно,   , спасибо,  , за,  , информация, \\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>заказывать   свитшот         спасибо   огромны...</td>\n",
       "      <td>19 мар 2018 в 11:09</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[заказывать,  , свитшот,        , спасибо,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td></td>\n",
       "      <td>22 июн 2018 в 12:07</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>заказывать   впервые   тут   кроссовок        ...</td>\n",
       "      <td>10 апр 2018 в 9:19</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[заказывать,  , впервые,  , тут,  , кроссовок,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment                 date  \\\n",
       "0    сегодня   забирать   на   почта    качество   ...   25 ноя 2017 в 6:46   \n",
       "1    вчера   получать    до   сей   пора   не   нар...  27 ноя 2017 в 16:20   \n",
       "2    спасибо   большой   все   отличный    очень   ...  28 ноя 2017 в 14:07   \n",
       "3                  спасибо   за   офигенный   кросс \\n   1 дек 2017 в 20:55   \n",
       "4    все   получать    переживать   за   качество  ...   2 дек 2017 в 17:22   \n",
       "..                                                 ...                  ...   \n",
       "968  приходить   штаны    никакой   повреждение    ...  28 мар 2020 в 14:18   \n",
       "969               ясно    спасибо   за   информация \\n   8 ноя 2019 в 16:12   \n",
       "970  заказывать   свитшот         спасибо   огромны...  19 мар 2018 в 11:09   \n",
       "971                                                     22 июн 2018 в 12:07   \n",
       "972  заказывать   впервые   тут   кроссовок        ...   10 апр 2018 в 9:19   \n",
       "\n",
       "     image  is_fake                                             lemmas  \n",
       "0     True        1  [сегодня,  , забирать,  , на,  , почта,   , ка...  \n",
       "1     True        1  [вчера,  , получать,   , до,  , сей,  , пора, ...  \n",
       "2     True        1  [спасибо,  , большой,  , все,  , отличный,   ,...  \n",
       "3     True        1       [спасибо,  , за,  , офигенный,  , кросс, \\n]  \n",
       "4     True        1  [все,  , получать,   , переживать,  , за,  , к...  \n",
       "..     ...      ...                                                ...  \n",
       "968   True        0  [приходить,  , штаны,   , никакой,  , поврежде...  \n",
       "969  False        0      [ясно,   , спасибо,  , за,  , информация, \\n]  \n",
       "970   True        0  [заказывать,  , свитшот,        , спасибо,  , ...  \n",
       "971  False        0                                                 []  \n",
       "972   True        0  [заказывать,  , впервые,  , тут,  , кроссовок,...  \n",
       "\n",
       "[922 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lem['lemmas'] = lemmatized_texts\n",
    "df_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим пустые леммы\n",
    "\n",
    "clean_lemmas = []\n",
    "regex = re.compile(r'\\s+')\n",
    "\n",
    "for text in lemmatized_texts:\n",
    "    clean_lemmas.append([i for i in text if not regex.search(i)])\n",
    "\n",
    "df_lem['lemmas'] = clean_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем стемминг лемм\n",
    "\n",
    "stemmer = SnowballStemmer(\"russian\", ignore_stopwords=True)\n",
    "stems = []\n",
    "\n",
    "for i in df_lem.lemmas:\n",
    "    row = []\n",
    "    for n in i:\n",
    "        row.append(stemmer.stem(n))\n",
    "    stems.append(row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>сегодня   забирать   на   почта    качество   ...</td>\n",
       "      <td>25 ноя 2017 в 6:46</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[сегодня, забирать, на, почта, качество, отлич...</td>\n",
       "      <td>[сегодн, забира, на, почт, качеств, отличн, уп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вчера   получать    до   сей   пора   не   нар...</td>\n",
       "      <td>27 ноя 2017 в 16:20</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[вчера, получать, до, сей, пора, не, нарадоват...</td>\n",
       "      <td>[вчер, получа, до, се, пор, не, нарадова, и, п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>спасибо   большой   все   отличный    очень   ...</td>\n",
       "      <td>28 ноя 2017 в 14:07</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[спасибо, большой, все, отличный, очень, нрави...</td>\n",
       "      <td>[спасиб, больш, все, отличн, очен, нрав]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment                 date  \\\n",
       "0  сегодня   забирать   на   почта    качество   ...   25 ноя 2017 в 6:46   \n",
       "1  вчера   получать    до   сей   пора   не   нар...  27 ноя 2017 в 16:20   \n",
       "2  спасибо   большой   все   отличный    очень   ...  28 ноя 2017 в 14:07   \n",
       "\n",
       "   image  is_fake                                             lemmas  \\\n",
       "0   True        1  [сегодня, забирать, на, почта, качество, отлич...   \n",
       "1   True        1  [вчера, получать, до, сей, пора, не, нарадоват...   \n",
       "2   True        1  [спасибо, большой, все, отличный, очень, нрави...   \n",
       "\n",
       "                                                stem  \n",
       "0  [сегодн, забира, на, почт, качеств, отличн, уп...  \n",
       "1  [вчер, получа, до, се, пор, не, нарадова, и, п...  \n",
       "2           [спасиб, больш, все, отличн, очен, нрав]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lem['stem'] = stems\n",
    "df_lem.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1817"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# узнаем число уникальных стемм\n",
    "\n",
    "vocabulary_stem = list(itertools.chain.from_iterable([i for i in df_lem['stem']]))\n",
    "len(set(vocabulary_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem.to_csv('out_bow.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_end = df_lem.stem\n",
    "\n",
    "stem_str = []\n",
    "for i in df_end:\n",
    "    stem_str.append(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['сегодн забира на почт качеств отличн упаковыва все аккуратн размер соответствова на ног сидет хорошо спасиб больш отличн сервис да еще и цен не заламыва быть заказыва еще',\n",
       " 'вчер получа до се пор не нарадова и про отз забыва спасиб']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_end = df_lem.copy()\n",
    "df_end['stem_str'] = stem_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"russian\"))\n",
    "\n",
    "bow_transformer = CountVectorizer(stop_words=stop_words ).fit(df_end.stem_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим список лемм фейковых отзывов\n",
    "lemmsFake = list(itertools.chain.from_iterable([i for i in df_lem.lemmas[df.is_fake == 1]]))\n",
    "\n",
    "# создадим список лемм реальных отзывов\n",
    "lemmsReal = list(itertools.chain.from_iterable([i for i in df_lem.lemmas[df.is_fake == 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density: 0.7789970652035217\n"
     ]
    }
   ],
   "source": [
    "reviews_bow = bow_transformer.transform(df_end.stem_str)\n",
    "real_bow = bow_transformer.transform(lemmsReal)\n",
    "fake_bow = bow_transformer.transform(lemmsFake)\n",
    "\n",
    "density = (100.0 * reviews_bow.nnz / (reviews_bow.shape[0] * reviews_bow.shape[1]))\n",
    "print('Density: {}'.format((density)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_all_words = reviews_bow.sum(axis=0)\n",
    "sum_real_words = real_bow.sum(axis=0)\n",
    "sum_fake_words = fake_bow.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_fake_freq = [(word, sum_fake_words[0, idx]) for word, idx in bow_transformer.vocabulary_.items()]\n",
    "words_fake_freq = sorted(words_fake_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_real_freq = [(word, sum_real_words[0, idx]) for word, idx in bow_transformer.vocabulary_.items()]\n",
    "words_real_freq = sorted(words_real_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_all_freq = [(word, sum_all_words[0, idx]) for word, idx in bow_transformer.vocabulary_.items()]\n",
    "words_all_freq = sorted(words_all_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Топ 10 слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('спасибо', 281),\n",
       " ('размер', 86),\n",
       " ('заказ', 78),\n",
       " ('магазин', 61),\n",
       " ('ваш', 40),\n",
       " ('супер', 38),\n",
       " ('продавец', 36),\n",
       " ('телефон', 33),\n",
       " ('менеджер', 24),\n",
       " ('цвет', 23)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для фэйковых отзывов\n",
    "\n",
    "words_fake_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('спасибо', 242),\n",
       " ('виктор', 153),\n",
       " ('размер', 133),\n",
       " ('подарок', 97),\n",
       " ('магазин', 89),\n",
       " ('носок', 85),\n",
       " ('кроссовок', 67),\n",
       " ('продавец', 67),\n",
       " ('вопрос', 60),\n",
       " ('носочек', 53)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для реальных отзывов\n",
    "\n",
    "words_real_freq[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вхождение в топ слова \"Виктор\" объясняется тем, что это имена владельца одного из крупных рассмотренных пабликов. Многие пользователи благодарят его в своих отзывах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('заказыва', 544),\n",
       " ('спасиб', 523),\n",
       " ('качеств', 443),\n",
       " ('очен', 374),\n",
       " ('приход', 289),\n",
       " ('размер', 219),\n",
       " ('отличн', 182),\n",
       " ('довольн', 181),\n",
       " ('хорош', 179),\n",
       " ('ве', 173)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для все отзывов\n",
    "\n",
    "words_all_freq[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общих лемм в топах реальных и фальшивых комментариев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_items = list((Counter(list(list(zip(*words_real_freq[:100]))[0])) & \n",
    "                     (Counter(list(list(zip(*words_fake_freq[:100]))[0])))))\n",
    "len(common_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(max_features=250000,  \n",
    "                                  stop_words=stop_words,\n",
    "                                  analyzer='word',\n",
    "                                  ngram_range=(1,2))\n",
    "\n",
    "TFIDF = word_vectorizer.fit_transform(stem_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОБУЧЕНИЕ МОДЕЛЕЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# шаблон вывода оценок качества модели\n",
    "\n",
    "def results(y_test, pred):\n",
    "    print('accuracy_score: {}'.format(round(accuracy_score(y_test, pred), 3)))    \n",
    "    print('f1_score: {}'.format(round(f1_score(y_test, pred), 3)))    \n",
    "    print('roc_auc_score: {}'.format(round(roc_auc_score(y_test, pred), 3)))\n",
    "    print('confusion_matrix: \\n{}'.format(confusion_matrix(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_lem.is_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cоздание тестовой и тренировочной выборок\n",
    "\n",
    "x = reviews_bow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.87\n",
      "f1_score: 0.87\n",
      "roc_auc_score: 0.87\n",
      "confusion_matrix: \n",
      "[[121  17]\n",
      " [ 19 120]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "pred = logreg.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'class_weight': {1: 0.7, 0: 0.3}, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': [.1, 1, 5, 10, 15, 50, 100],\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'class_weight': ['balanced', {1: 0.7, 0: 0.3}]}\n",
    "\n",
    "clf = LogisticRegression(random_state=21)\n",
    "gridSearchCV = GridSearchCV(clf, parameters, scoring='roc_auc')\n",
    "gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "gridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.87\n",
      "f1_score: 0.87\n",
      "roc_auc_score: 0.87\n",
      "confusion_matrix: \n",
      "[[121  17]\n",
      " [ 19 120]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "pred = logreg.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.881\n",
      "f1_score: 0.885\n",
      "roc_auc_score: 0.881\n",
      "confusion_matrix: \n",
      "[[117  21]\n",
      " [ 12 127]]\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train, y_train)\n",
    "pred = bnb.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.334}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\"alpha\": np.linspace(0.001, 1, 100)}\n",
    "\n",
    "clf = BernoulliNB()\n",
    "gridSearchCV = GridSearchCV(clf, parameters, scoring='roc_auc')\n",
    "gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "gridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.892\n",
      "f1_score: 0.896\n",
      "roc_auc_score: 0.892\n",
      "confusion_matrix: \n",
      "[[118  20]\n",
      " [ 10 129]]\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB(alpha=0.334)\n",
    "bnb.fit(x_train, y_train)\n",
    "pred = bnb.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.657\n",
      "f1_score: 0.578\n",
      "roc_auc_score: 0.658\n",
      "confusion_matrix: \n",
      "[[117  21]\n",
      " [ 74  65]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 8}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\"n_neighbors\": [i for i in range(1, 10)]}\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "gridSearchCV = GridSearchCV(clf, parameters, scoring='roc_auc')\n",
    "gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "gridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.585\n",
      "f1_score: 0.378\n",
      "roc_auc_score: 0.586\n",
      "confusion_matrix: \n",
      "[[127  11]\n",
      " [104  35]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(x_train, y_train)\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.83\n",
      "f1_score: 0.81\n",
      "roc_auc_score: 0.831\n",
      "confusion_matrix: \n",
      "[[130   8]\n",
      " [ 39 100]]\n"
     ]
    }
   ],
   "source": [
    "rfclf = RandomForestClassifier()\n",
    "rfclf.fit(x_train, y_train)\n",
    "pred = rfclf.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state=21# Select best RandomForest model with cross validation\n",
    "possibleRandomForestParameters = [{\n",
    "        'n_estimators': [10, 25, 50, 100],\n",
    "        'max_depth': [5, 10, 50, 100, 250, 500, 1000],\n",
    "        'criterion': ['gini', 'entropy']}]\n",
    "\n",
    "randomForestModel = RandomForestClassifier(random_state=41)\n",
    "\n",
    "gridSearchCV = GridSearchCV(estimator=randomForestModel,\n",
    "                            param_grid=possibleRandomForestParameters,\n",
    "                            scoring='roc_auc')\n",
    "gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "gridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.856\n",
      "f1_score: 0.848\n",
      "roc_auc_score: 0.856\n",
      "confusion_matrix: \n",
      "[[125  13]\n",
      " [ 27 112]]\n"
     ]
    }
   ],
   "source": [
    "rfclf = RandomForestClassifier(criterion='entropy', max_depth=50,\n",
    "                               n_estimators=100)\n",
    "rfclf.fit(x_train, y_train)\n",
    "pred = rfclf.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.838\n",
      "f1_score: 0.831\n",
      "roc_auc_score: 0.838\n",
      "confusion_matrix: \n",
      "[[121  17]\n",
      " [ 28 111]]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(x_train, y_train)\n",
    "pred = gb.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 48}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'n_estimators': range(2, 50, 2),\n",
    "         'max_depth': range(3, 20, 2)}\n",
    "gsearch1 = GridSearchCV(estimator=GradientBoostingClassifier(random_state=21),\n",
    "                       param_grid=param,\n",
    "                       scoring='roc_auc')\n",
    "gsearch1.fit(x_train, y_train)\n",
    "\n",
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 60, 'min_samples_split': 300}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'min_samples_split': range(100, 801, 200),\n",
    "         'min_samples_leaf': range(60, 101, 10)}\n",
    "gsearch2 = GridSearchCV(estimator=GradientBoostingClassifier(random_state=21),\n",
    "                       param_grid=param,\n",
    "                       scoring='roc_auc')\n",
    "gsearch2.fit(x_train, y_train)\n",
    "\n",
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.765\n",
      "f1_score: 0.79\n",
      "roc_auc_score: 0.765\n",
      "confusion_matrix: \n",
      "[[ 90  48]\n",
      " [ 17 122]]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=48, max_depth=5,\n",
    "                                min_samples_split=300, min_samples_leaf=60)\n",
    "gb.fit(x_train, y_train)\n",
    "pred = gb.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.791\n",
      "f1_score: 0.758\n",
      "roc_auc_score: 0.791\n",
      "confusion_matrix: \n",
      "[[128  10]\n",
      " [ 48  91]]\n"
     ]
    }
   ],
   "source": [
    "SVC = make_pipeline(StandardScaler(with_mean=False), SVC(random_state=21))\n",
    "SVC.fit(x_train, y_train)\n",
    "pred = SVC.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 10.0, 'svc__gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "param_grid_pipeline = {'svc__C': 10. ** np.arange(-3, 3),\n",
    "                       'svc__gamma': 10. ** np.arange(-3, 3)}\n",
    "\n",
    "scaler_pipe = make_pipeline(StandardScaler(with_mean=False), SVC())\n",
    "grid = GridSearchCV(scaler_pipe, param_grid=param_grid_pipeline, cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.769\n",
      "f1_score: 0.756\n",
      "roc_auc_score: 0.769\n",
      "confusion_matrix: \n",
      "[[114  24]\n",
      " [ 40  99]]\n"
     ]
    }
   ],
   "source": [
    "SVC = make_pipeline(StandardScaler(with_mean=False), SVC(C=10.0, gamma=0.001))\n",
    "SVC.fit(x_train, y_train)\n",
    "pred = SVC.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cоздание тестовой и тренировочной выборок\n",
    "\n",
    "x = stem_str\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(TFIDF, y, test_size=0.30, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.856\n",
      "f1_score: 0.86\n",
      "roc_auc_score: 0.855\n",
      "confusion_matrix: \n",
      "[[114  24]\n",
      " [ 16 123]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "pred = logreg.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'class_weight': 'balanced', 'penalty': 'l2'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': [.1, 1, 5, 10, 15, 50, 100],\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'class_weight': ['balanced', {1: 0.7, 0: 0.3}]}\n",
    "\n",
    "clf = LogisticRegression()\n",
    "gridSearchCV = GridSearchCV(clf, parameters, scoring='roc_auc')\n",
    "gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "gridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.856\n",
      "f1_score: 0.852\n",
      "roc_auc_score: 0.856\n",
      "confusion_matrix: \n",
      "[[122  16]\n",
      " [ 24 115]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=100)\n",
    "logreg.fit(x_train, y_train)\n",
    "pred = logreg.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.848\n",
      "f1_score: 0.843\n",
      "roc_auc_score: 0.849\n",
      "confusion_matrix: \n",
      "[[122  16]\n",
      " [ 26 113]]\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train, y_train)\n",
    "pred = bnb.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.8385454545454546}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\"alpha\": np.linspace(0.001, 1, 100)}\n",
    "\n",
    "clf = BernoulliNB()\n",
    "gridSearchCV = GridSearchCV(clf, parameters, scoring='roc_auc')\n",
    "gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "gridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.859\n",
      "f1_score: 0.86\n",
      "roc_auc_score: 0.859\n",
      "confusion_matrix: \n",
      "[[118  20]\n",
      " [ 19 120]]\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB(alpha=0.838)\n",
    "bnb.fit(x_train, y_train)\n",
    "pred = bnb.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.505\n",
      "f1_score: 0.402\n",
      "roc_auc_score: 0.506\n",
      "confusion_matrix: \n",
      "[[94 44]\n",
      " [93 46]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\"n_neighbors\": [i for i in range(1, 8)]}\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "gridSearchCV = GridSearchCV(clf, parameters, scoring='roc_auc')\n",
    "gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "gridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.606\n",
      "f1_score: 0.355\n",
      "roc_auc_score: 0.608\n",
      "confusion_matrix: \n",
      "[[138   0]\n",
      " [109  30]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(x_train, y_train)\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.816\n",
      "f1_score: 0.812\n",
      "roc_auc_score: 0.816\n",
      "confusion_matrix: \n",
      "[[116  22]\n",
      " [ 29 110]]\n"
     ]
    }
   ],
   "source": [
    "rfclf = RandomForestClassifier()\n",
    "rfclf.fit(x_train, y_train)\n",
    "pred = rfclf.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 250, 'n_estimators': 100}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select best RandomForest model with cross validation\n",
    "possibleRandomForestParameters = [{\n",
    "        'n_estimators': [10, 25, 50, 100],\n",
    "        'max_depth': [5, 10, 50, 100, 250, 500, 1000],\n",
    "        'criterion': ['gini', 'entropy']}]\n",
    "\n",
    "randomForestModel = RandomForestClassifier()\n",
    "\n",
    "gridSearchCV = GridSearchCV(estimator=randomForestModel,\n",
    "                            param_grid=possibleRandomForestParameters,\n",
    "                            scoring='roc_auc')\n",
    "gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "gridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.859\n",
      "f1_score: 0.855\n",
      "roc_auc_score: 0.859\n",
      "confusion_matrix: \n",
      "[[123  15]\n",
      " [ 24 115]]\n"
     ]
    }
   ],
   "source": [
    "rfclf = RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=50)\n",
    "rfclf.fit(x_train, y_train)\n",
    "pred = rfclf.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.823\n",
      "f1_score: 0.834\n",
      "roc_auc_score: 0.823\n",
      "confusion_matrix: \n",
      "[[105  33]\n",
      " [ 16 123]]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(x_train, y_train)\n",
    "pred = gb.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 46}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'n_estimators': range(2, 50, 2),\n",
    "         'max_depth': range(3, 20, 2)}\n",
    "gsearch1 = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                       param_grid=param,\n",
    "                       scoring='roc_auc')\n",
    "gsearch1.fit(x_train, y_train)\n",
    "\n",
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 60, 'min_samples_split': 300}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'min_samples_split': range(100, 801, 200),\n",
    "         'min_samples_leaf': range(60, 101, 10)}\n",
    "gsearch2 = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                       param_grid=param,\n",
    "                       scoring='roc_auc')\n",
    "gsearch2.fit(x_train, y_train)\n",
    "\n",
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.773\n",
      "f1_score: 0.789\n",
      "roc_auc_score: 0.772\n",
      "confusion_matrix: \n",
      "[[ 96  42]\n",
      " [ 21 118]]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=46, max_depth=9,\n",
    "                                min_samples_split=300, min_samples_leaf=60)\n",
    "gb.fit(x_train, y_train)\n",
    "pred = gb.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начальный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.639\n",
      "f1_score: 0.451\n",
      "roc_auc_score: 0.64\n",
      "confusion_matrix: \n",
      "[[136   2]\n",
      " [ 98  41]]\n"
     ]
    }
   ],
   "source": [
    "SVC = make_pipeline(StandardScaler(with_mean=False), SVC())\n",
    "SVC.fit(x_train, y_train)\n",
    "pred = SVC.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 100.0, 'svc__gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "param_grid_pipeline = {'svc__C': 10. ** np.arange(-3, 3),\n",
    "                       'svc__gamma': 10. ** np.arange(-3, 3)}\n",
    "\n",
    "scaler_pipe = make_pipeline(StandardScaler(with_mean=False), SVC())\n",
    "grid = GridSearchCV(scaler_pipe, param_grid=param_grid_pipeline,\n",
    "                    cv=5, scoring='roc_auc')\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конечный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.606\n",
      "f1_score: 0.355\n",
      "roc_auc_score: 0.608\n",
      "confusion_matrix: \n",
      "[[138   0]\n",
      " [109  30]]\n"
     ]
    }
   ],
   "source": [
    "SVC = make_pipeline(StandardScaler(with_mean=False),\n",
    "                    SVC(C=100.0, gamma=0.001))\n",
    "SVC.fit(x_train, y_train)\n",
    "pred = SVC.predict(x_test)\n",
    "\n",
    "results(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
